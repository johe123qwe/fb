import warnings
import click
import pandas as pd
import threading

warnings.simplefilter(action="ignore", category=FutureWarning)
from datetime import datetime
import os
import random
import sqlite3
import time
from zoneinfo import ZoneInfo
import gspread
import os
import getfb_posts
# from facebook_scraper import *
from google.oauth2 import service_account
from googleapiclient.discovery import build
from skpy import Skype
import group_info_config

'''å®‰è£…
pip install -q -U google-generativeai
pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib
pip install gspread click
'''

'''æ›´æ–°æ—¥å¿—
20250318 æ”¹ä¸ºæ‰¹é‡ä¸Šä¼ æ•°æ®
20240419 å¢åŠ è·å–æŠ–éŸ³çš„æ•°æ®
'''


#### é…ç½®åŒºåŸŸstart ####

# é—´éš”æ—¶é—´
time_a = 9
time_b = 13
#### é…ç½®åŒºåŸŸend ####
# Skype è´¦å·ã€å¯†ç 
sk_username = group_info_config.SK_USERNAME
sk_password = group_info_config.SK_PASSWORD
groupid = group_info_config.GROUP_ID

# è¯»å–è°·æ­Œè¡¨æ ¼ï¼Œ token.json è·å–ä¸º google sheet API
SERVICE_ACCOUNT_FILE = "token.json"
SCOPES = [
    "https://www.googleapis.com/auth/drive",
    "https://www.googleapis.com/auth/spreadsheets",
]
creds = None
creds = service_account.Credentials.from_service_account_file(
    SERVICE_ACCOUNT_FILE, scopes=SCOPES
)

service_account_file = os.path.abspath("token.json")
service = build("sheets", "v4", credentials=creds)
sheet = service.spreadsheets()



sqlilt_db = os.path.join(os.path.dirname(__file__), "sqlite3", "de_post_group.db")

tday = datetime.now()  # å½“å‰æ—¶é—´
# tday_ = tday.strftime("%Y-%m-%d %H:%M:%S")  # å½“å‰æ—¥æœŸæ—¶é—´
tday__ = tday.strftime("%Y-%m-%d")  # å½“å‰æ—¥æœŸæ—¶é—´

def time_now(timezone):
    """è·å–å½“å‰æ—¥æœŸ"""
    time_now = datetime.now(ZoneInfo(timezone)).strftime("%Y-%m-%d %H:%M:%S")
    return time_now


emoji_list = [
    "â˜˜ï¸",
    "ğŸ¥•",
    "ğŸ€",
    "ğŸš—",
    "ğŸŠ",
    "ğŸ‹",
    "ğŸ",
    "ğŸ¥­",
    "ğŸ",
    "ğŸ“",
    "ğŸ’",
    "ğŸ†",
    "ğŸ«’",
    "ğŸ…",
    "ğŸ”",
    "ğŸ—“ï¸",
    "ğŸŸ¢",
    "ğŸ”µ",
    "ğŸ˜Š",
    "ğŸ˜¬",
    "ğŸ¥º",
    "ğŸ‘€",
    "ğŸ«‘",
    "ğŸŒ¸",
    "ğŸµï¸",
    "ğŸŒº",
    "ğŸŒ»",
    "ğŸš—",
    "ğŸš•",
    "ğŸš™",
    "ğŸ‘",
    "ğŸŒŸ",
    "â˜€ï¸",
    "ğŸ¥¦",
    "ğŸ¥¬",
    "ğŸ¥’",
    "ğŸŒ½",
    "ğŸ†",
    "ğŸ",
    "ğŸ’–",
    "ğŸ’",
    "ğŸ§¡",
    "âœ…",
    "ğŸ’",
    "ğŸ¥€",
]


def gspread_clint():
    """Connects to a Google Sheet."""
    scope = [
        "https://spreadsheets.google.com/feeds",
        "https://www.googleapis.com/auth/drive",
    ]
    creds = service_account.Credentials.from_service_account_file(
        service_account_file, scopes=scope
    )
    client = gspread.authorize(creds)
    return client

def list_sheet(sheet_key):
    client = gspread_clint()
    try:
        sheet = client.open_by_key(sheet_key).worksheets()
        return sheet
    except gspread.exceptions.WorksheetNotFound:
        return None

def get_id_name(id) -> dict:
    sheet_names = list_sheet(id)
    id_name_dic = {item.title : item.id for item in sheet_names}
    return id_name_dic

def get_data(sheet_name, sheet_range, sheet_id):
    """è·å–è¡¨æ ¼æ•°æ®sheet_name, sheet_range, sheet_id"""
    info_data = ""
    SCOPES = [
        "https://www.googleapis.com/auth/drive",
        "https://www.googleapis.com/auth/spreadsheets",
    ]
    sheet = service.spreadsheets()
    name_range = "{}!{}".format(sheet_name, sheet_range)
    try:
        result = sheet.values().get(spreadsheetId=sheet_id, range=name_range).execute()
        info_data = result.get("values", [])
        df = pd.DataFrame(info_data)
        return df, info_data
    except Exception as e:
        info = "è¯»å–å·¥ä½œè¡¨æ•°æ® {} {} å¤±è´¥,è¯·æ£€æŸ¥. {}".format(sheet_id, sheet_name, e)
        print(60, e)
        return 0


def get_group_id(value, column=2):
    """è·å–å°ç»„ID"""
    group_id = []
    for row in range(0, value.shape[0]):
        # print(96, value.iat[row, column])
        group_id.append(value.iat[row, column])
    return group_id


def get_fb_group_member(group_id, cookie):
    """è·å–å°ç»„äººæ•°"""
    #  cookies='/Users/xiaoyu/develop/pyscript/de_post/cookie_files/facebook_cookiesde02.txt'
    try:
        ginfo = get_group_info(
            group_id,
            cookies=cookie,
        )
        return ginfo["members"]
    except Exception as e:
        print(144, e)
        return -1


def get_fb_group_member2(group_id):
    """è·å–å°ç»„äººæ•°, ä¸ä½¿ç”¨ cookie"""
    try:
        ginfo = get_group_info(
            group_id,
        )
        return ginfo["members"]
    except Exception as e:
        print(155, e)
        return -1


def getmembers(group_ids):
    """è·å–å°ç»„äººæ•°,è¾“å‡ºä¸ºåˆ—è¡¨"""
    members = []
    for id in group_ids:
        row = []
        if id != None:
            nums = get_fb_group_member(id, "./cookie_files/facebook_cookiesde02.txt")
            try_times = 0
            while nums == -1:
                print("stop10 {}".format(id))
                try_times += 1
                time.sleep(10)
                if 5 >= try_times > 1:
                    nums = get_fb_group_member2(id)
                elif 7 >= try_times > 5:
                    nums = get_fb_group_member(
                        id, "./cookie_files/facebook_cookiesen02.txt"
                    )
                elif 8 >= try_times > 7:
                    nums = get_fb_group_member(
                        id, "./cookie_files/facebook_cookiesen03.txt"
                    )
                elif try_times > 8:
                    nums = -1
            else:
                print("å°ç»„", nums, id)
                row.append(nums)
                time.sleep(5)
        elif id == None:
            row.append(None)
        members.append(row)
    return members


def send_telegram(msg):
    import telegram

    tel_group_id = "175568461"
    token = "783640552:AAGykkJBhYGfRD_Qj8LKXGECuX9hkFLsEXc"

    bot = telegram.Bot(token)
    try:
        bot.send_message(chat_id=tel_group_id, text=msg)
    except Exception as e:
        logger.error("Telegram sends information failed {} {}".format(msg, e))

def get_tk_posts(group_id):
    '''è·å–æŠ–éŸ³æ•°æ®
    ç²‰ä¸ã€å…³æ³¨ã€å¥½å‹ã€ç‚¹èµ'''
    count = 0
    result = getfb_posts.get_tiktok(group_id)
    while result[0] == None and count < 3:
        count += 1
        time.sleep(10)
        result = getfb_posts.get_tiktok(group_id)
    return result

# å†™ä¸€ä¸ªè¯»å–æ–‡ä»¶å‡½æ•°
def read_file():
    '''è¯»å–ä¸€ä¸ªæ–‡ä»¶æ–‡ä»¶'''

def get_fb_posts(group_id):
    result = getfb_posts.get_fb_posts_local(group_id)
    print(group_id, "å‘å¸–æ•°", result)
    trys = 0
    while result[0] == "toomany":
        trys += 1
        if trys < 10:
            result = getfb_posts.get_fb_posts_local(group_id)
            print(group_id, "å‘å¸–æ•°", result)
            time.sleep(4)
        else:
            # send_telegram("å°ç»„ {} ä»Šæ—¥å‘å¸–æ•°è·å–å¤±è´¥, {}".format(group_id, result[1]))
            break
    return result[0], result[1]
    # api = CrawlingAPI({ 'token': 'EHNKnzONlTCNVdD6owxB9Q' })
    # response = api.get('https://www.facebook.com/groups/{}/about'.format(group_id))
    # while response['status_code'] == 200:
    #     text = response['body'].decode("utf-8")
    #     result = re.search(r'"number_of_posts_in_last_day":(.*?),', text)
    #     if result:
    #         return result.group(1)
    #     else:
    #         return 0
    # else:
    #     time.sleep(3)
    #     get_fb_posts(group_id)


def getposts(group_ids):
    """è·å–å°ç»„å½“æ—¥å¸–å­æ•°å’Œæ€»å¸–å­æ•°,è¾“å‡ºä¸ºåˆ—è¡¨"""
    posts_all = []
    member_all = []
    for id in group_ids:
        posts = []
        members = []
        time.sleep(10)
        if id != None:
            result = get_fb_posts(id)
            nums = result[0]
            posts.append(nums)
            members.append(result[1])
        elif id == None:
            posts.append(None)
            members.append(None)
        posts_all.append(posts)
        member_all.append(members)
    return posts_all, member_all


def upload_data(result, sheet_range, update_sheet_id):
    """ä¸Šä¼ æ•°æ®"""
    body = {"values": result}

    # ä½¿ç”¨ update å‚æ•°å†™å…¥æ•°æ®
    sheet.values().update(
        spreadsheetId=update_sheet_id,
        range=sheet_range,
        valueInputOption="USER_ENTERED",
        body=body,
    ).execute()

def upload_data_batch(result, sheet_name, sheet_range, update_sheet_id):
    """æ‰¹é‡ä¸Šä¼ æ•°æ®"""
    client = gspread_clint()
    sheet = client.open_by_key(update_sheet_id).worksheet(sheet_name)
    sheet.batch_update([
        {
            'range': sheet_range,
            'values': result
        }
    ])

def input_database(group_info, max_retries=5, base_delay=0.1):
    """å°†çˆ¬å–çš„å¸–å­å†™å…¥æ•°æ®åº“ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    
    for attempt in range(max_retries):
        try:
            conn = sqlite3.connect(sqlilt_db, timeout=30)  # è®¾ç½®30ç§’è¶…æ—¶
            c = conn.cursor()
            
            # å¼€å¯WALæ¨¡å¼ä»¥æé«˜å¹¶å‘æ€§èƒ½
            c.execute("PRAGMA journal_mode=WAL")
            
            c.execute(
                """create table if not exists groups_info(
                    id INTEGER PRIMARY KEY, 
                    å§“å text, 
                    å°ç»„åå­— text, 
                    å°ç»„ID text, 
                    æ—¥æœŸ text, 
                    å°ç»„æ€»äººæ•° INTEGER, 
                    å°ç»„å½“æ—¥å¸–å­æ•° INTEGER
                )"""
            )
            
            c.executemany(
                "INSERT INTO groups_info(å§“å, å°ç»„åå­—, å°ç»„ID, æ—¥æœŸ, å°ç»„æ€»äººæ•°, å°ç»„å½“æ—¥å¸–å­æ•°) VALUES(?,?,?,?,?,?)",
                group_info,
            )
            
            conn.commit()
            conn.close()
            print(f"æ•°æ®åº“æ“ä½œæˆåŠŸï¼Œå°è¯•æ¬¡æ•°: {attempt + 1}")
            return  # æˆåŠŸåˆ™é€€å‡ºå‡½æ•°
            
        except sqlite3.OperationalError as e:
            if "database is locked" in str(e):
                if attempt < max_retries - 1:
                    # æŒ‡æ•°é€€é¿ + éšæœºå»¶è¿Ÿ
                    delay = base_delay * (2 ** attempt) + random.uniform(0, 0.1)
                    print(f"æ•°æ®åº“è¢«é”å®šï¼Œç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥ï¼Œ{delay:.2f}ç§’åé‡è¯•...")
                    time.sleep(delay)
                    continue
                else:
                    print(f"é‡è¯•{max_retries}æ¬¡åä»ç„¶å¤±è´¥")
                    raise
            else:
                # å…¶ä»–ç±»å‹çš„é”™è¯¯ç›´æ¥æŠ›å‡º
                raise
        except Exception as e:
            print(f"å‘ç”Ÿå…¶ä»–é”™è¯¯: {e}")
            raise
        finally:
            # ç¡®ä¿è¿æ¥è¢«å…³é—­
            try:
                if 'conn' in locals():
                    conn.close()
            except:
                pass

def tk_input_database(group_info):
    """å°†çˆ¬å–çš„tiktokæ•°æ®å†™å…¥æ•°æ®åº“"""
    conn = sqlite3.connect(sqlilt_db)
    c = conn.cursor()

    # c.execute("""drop table if exists all_posts_info""")
    c.execute(
        """create table if not exists tiktok_info(id INTEGER PRIMARY KEY, å§“å text, ä¸»é¡µid text, æ—¥æœŸ text, ç²‰ä¸æ•° INTEGER, å…³æ³¨æ•° INTEGER, å¥½å‹æ•° INTEGER, ç‚¹èµæ•° INTEGER)"""
    )
    # print(232, group_info)
    c.executemany(
        "INSERT INTO tiktok_info(å§“å, ä¸»é¡µid, æ—¥æœŸ, ç²‰ä¸æ•°, å…³æ³¨æ•°, å¥½å‹æ•°, ç‚¹èµæ•°) VALUES(?,?,?,?,?,?,?)",
        group_info,
    )
    conn.commit()
    conn.close()


def db_insert(group_info, tday, members, posts):
    """æ’å…¥æ•°æ®åº“çš„æ•°æ®"""
    infos = []
    for row in range(0, group_info.shape[0]):
        group_row = []
        # print(96, value.iat[row, 2])
        group_row.append(group_info.iat[row, 0]),
        group_row.append(group_info.iat[row, 1]),
        group_row.append(group_info.iat[row, 2]),
        group_row.append(tday),
        group_row.append(members[row][0]),
        group_row.append(posts[row][0]),
        infos.append(group_row)
    return infos


def get_dic(value):
    """ç”Ÿæˆå°ç»„idå’Œäººæ•°çš„å­—å…¸"""
    dic = {}
    for row in range(0, len(value)):
        dic[value[row][0]] = value[row][3]
    return dic


def query_database(vauledate):
    """æŸ¥è¯¢å°ç»„å¢é•¿äººæ•°"""
    conn = sqlite3.connect(sqlilt_db)
    c = conn.cursor()

    c.execute(
        '''SELECT "å°ç»„ID", date("æ—¥æœŸ") AS "æ—¥æœŸ", MAX("æ—¥æœŸ") AS "æœ€åæ—¶é—´", "å°ç»„æ€»äººæ•°" FROM groups_info WHERE date("æ—¥æœŸ") = date({}) GROUP BY "å°ç»„ID"'''.format(
            vauledate
        )
    )

    query_result = c.fetchall()  # å½“å¤©æœ€è¿‘ä¸€æ¬¡çš„å°ç»„äººæ•°
    t_dic = get_dic(query_result)
    # print(346, t_dic)
    return t_dic

def query_database_tk(vauledate):
    """æŸ¥è¯¢tkå°ç»„å¢é•¿äººæ•°"""
    conn = sqlite3.connect(sqlilt_db)
    c = conn.cursor()

    c.execute(
        '''SELECT "ä¸»é¡µid", date("æ—¥æœŸ") AS "æ—¥æœŸ", MAX("æ—¥æœŸ") AS "æœ€åæ—¶é—´", "ç²‰ä¸æ•°" FROM tiktok_info WHERE date("æ—¥æœŸ") = date({}) GROUP BY "ä¸»é¡µid"'''.format(
            vauledate
        )
    )

    query_result = c.fetchall()  # å½“å¤©æœ€è¿‘ä¸€æ¬¡çš„å°ç»„äººæ•°
    t_dic = get_dic(query_result)
    # print(346, t_dic)
    return t_dic

def query_database2_tk(column_name, vauledate):
    """æŸ¥è¯¢tiktokå‘å¸–æ•°"""
    conn = sqlite3.connect(sqlilt_db)
    c = conn.cursor()

    c.execute(
        '''SELECT "ä¸»é¡µid", date("æ—¥æœŸ") AS "æ—¥æœŸ", MAX("æ—¥æœŸ") AS "æœ€åæ—¶é—´", "{}" FROM tiktok_info WHERE date("æ—¥æœŸ") = date({}) GROUP BY "ä¸»é¡µid"'''.format(
            column_name, vauledate
        )
    )

    query_result = c.fetchall()  # å½“å¤©æœ€è¿‘ä¸€æ¬¡çš„å°ç»„äººæ•°
    t_dic = get_dic(query_result)
    return t_dic

def query_database2(vauledate):
    """æŸ¥è¯¢å°ç»„å‘å¸–æ•°"""
    conn = sqlite3.connect(sqlilt_db)
    c = conn.cursor()

    c.execute(
        '''SELECT "å°ç»„ID", date("æ—¥æœŸ") AS "æ—¥æœŸ", MAX("æ—¥æœŸ") AS "æœ€åæ—¶é—´", "å°ç»„å½“æ—¥å¸–å­æ•°" FROM groups_info WHERE date("æ—¥æœŸ") = date({}) GROUP BY "å°ç»„ID"'''.format(
            vauledate
        )
    )

    query_result = c.fetchall()  # å½“å¤©æœ€è¿‘ä¸€æ¬¡çš„å°ç»„äººæ•°
    t_dic = get_dic(query_result)
    return t_dic


def count_group(t_dic, b_dic):
    """è®¡ç®—å½“å¤©ä¸å‰ä¸€å¤©çš„å°ç»„äººæ•°å·®ï¼Œç”Ÿæˆå­—å…¸
    t_dic: å½“å¤©çš„å°ç»„äººæ•°
    b_dic: å‰ä¸€å¤©çš„å°ç»„äººæ•°"""
    dic = {}
    for key, value in t_dic.items():
        if (
            str(t_dic.get(key)).replace(",", "").isdigit()
            and str(b_dic.get(key)).replace(",", "").isdigit()
        ):
            # print('å½“å¤©å°ç»„äººæ•°', t_dic.get(key), key)
            # print('å‰ä¸€å¤©å°ç»„äººæ•°', b_dic.get(key), key)
            increase = int(str(t_dic.get(key)).replace(",", "")) - int(
                str(b_dic.get(key)).replace(",", "")
            )
            dic[key] = increase
    return dic


def get_upload_group_increase(ids, dic):
    """è·å–ç”¨äºä¸Šä¼ è¡¨æ ¼çš„å°ç»„å¢é•¿äººæ•°"""
    nums = []
    for id in range(0, len(ids)):
        row = []
        row.append(dic.get(ids[id], 0))
        nums.append(row)
    return nums


def update_time(sheet_name, sheet_id, timezone, sheet_range="E1", content_title="æ€»äººæ•°"):
    """æ›´æ–°æ—¶é—´"""
    current_time = []
    upoad_current_time = []
    time_now = datetime.now(ZoneInfo(timezone)).strftime("%Y-%m-%d %H:%M:%S")
    update_time = time_now + " {}".format(content_title)
    current_time.append(update_time)
    upoad_current_time.append(current_time)
    body6 = {"values": upoad_current_time}
    # ä½¿ç”¨ update å‚æ•°å†™å…¥æ•°æ®
    sheet.values().update(
        spreadsheetId=sheet_id,
        range="{}!{}".format(sheet_name, sheet_range),
        valueInputOption="USER_ENTERED",
        body=body6,
    ).execute()


def send_sk(info, SK_ID):
    """å‘é€ skype ä¿¡æ¯,
    rich=True ä¸ºå¯Œæ–‡æœ¬ï¼Œå¯ä»¥@ç”¨æˆ·ï¼Œä½†æ˜¯å¼€å¯richå
    ä½¿ç”¨çš„è¡¨æƒ…ä¸èƒ½ä¸ºskypeè‡ªå¸¦çš„è¡¨æƒ…ï¼Œå¯ä»¥ä½¿ç”¨windowsæˆ–macç³»ç»Ÿ
    è‡ªå¸¦çš„è¡¨æƒ…ã€‚"""
    try:
        sk = Skype(sk_username, sk_password)
        ch = sk.chats[SK_ID]  # ç»™å°ç»„å‘ä¿¡æ¯
        ch.sendMsg(info, rich=False)
        return 1
    except Exception as e:
        return 0


def group_sort_tk(sheet_name, sheet_id, send_type=7):
    """å°ç»„æ¥äººæ’å"""
    result = get_data(sheet_name, "B4:J", sheet_id)
    df = result[0]
    # print(df, 498)
    # æå–å§“æ°éƒ¨åˆ†
    df[0] = df[0].str.split('-').str[1].str[:-3]

    # è·å–ä¸åŒçš„äººå
    unique_names = df[0].unique()
    print("æ•°æ®ä¸­çš„äººåæœ‰:", unique_names)

    name_count_dic = {}
    for name in unique_names:
        total = pd.to_numeric(df[df[0].str.contains(name)][int(send_type)], errors='coerce').sum()
        name_count_dic[name] = total
    print(name_count_dic)

    # æ ¹æ®å­—å…¸çš„å€¼è¿›è¡Œæ’åº
    sorted_data = sorted(name_count_dic.items(), key=lambda x: x[1], reverse=True)
    top_num = sorted_data[:20]
    return top_num

def group_sort(sheet_name, sheet_id):
    """å°ç»„æ¥äººæ’å"""
    result = get_data(sheet_name, "B4:F", sheet_id)
    sorted_list = sorted(result[1], key=lambda x: int(x[4]))
    nlist = sorted_list[-10:]
    for index in range(-len(sorted_list), -10):
        if sorted_list[-10][4] == sorted_list[index][4]:
            nlist.insert(0, sorted_list[index])
    nlist.reverse()
    return nlist, result[1]


def skype_info(li):
    content = "å¾·è¯­è‡ªå»ºå°ç»„ {} æŠ¥å‘Š\n".format(tday__)
    for index in range(len(li)):
        result = "{}{} {} æ–°å¢ {}".format(
            random.sample(emoji_list, 1)[0], li[index][0], li[index][1], li[index][3]
        )
        content += result + "\n"
    return content

def get_titok_post_info(group_ids):
    """è·å–å°ç»„å½“æ—¥å¸–å­æ•°å’Œæ€»å¸–å­æ•°,è¾“å‡ºä¸ºåˆ—è¡¨"""
    fans_all = []
    follows_all = []
    friends_all = []
    likes_all = []
    for id in group_ids:
        fans = []
        follows = []
        friends = []
        likes = []
        time.sleep(2)
        print(id, 478)
        if id != None:
            result = get_tk_posts(id)
            if result != None:
                fans.append(result[0])
                follows.append(result[1])
                friends.append(result[2])
                likes.append(result[3])
            else:
                fans.append(None)
                follows.append(None)
                friends.append(None)
                likes.append(None)
        elif id == None:
            fans.append(None)
            follows.append(None)
            friends.append(None)
            likes.append(None)
        fans_all.append(fans)
        follows_all.append(follows)
        friends_all.append(friends)
        likes_all.append(likes)
    return fans_all, follows_all, friends_all, likes_all

def upload_tk_today(sheet_name, sheet_id, result_all):
    '''ä¸Šä¼ æŠ–éŸ³ä»Šæ—¥æ•°æ®'''
    upload_data_list = []
    # print('åˆ—è¡¨æ•°ç»„é•¿åº¦:', len(result_all[0]))
    for row in range(len(result_all[0])):
        fans = result_all[0][row][0]
        if fans == None:
            fans = 0

        followers = result_all[1][row][0]
        if followers == None:
            followers = 0

        friends = result_all[2][row][0]
        if friends == None:
            friends = 0

        likes = result_all[3][row][0]
        if likes == None:
            likes = 0

        upload_data_list.append([fans, followers, friends, likes])
    # print(upload_data_list, 515)
    upload_data(upload_data_list, "{}!D4:G".format(sheet_name), sheet_id)
    return upload_data_list

def upload_tk_fri_fol_increase(sheet_name, sheet_id, ids):
    '''ä¸Šä¼ æ¯æ—¥å¢é•¿çš„å¥½å‹å’Œå…³æ³¨æ•°é‡'''
    sheet_columns_followers = ['I', 'L', 'O', 'R', 'U', 'X', 
                           'AA', 'AD', 'AG', 'AJ', 'AM', 
                           'AP', 'AS', 'AV', 'AY', 'BB']

    sheet_columns_friends = ['J', 'M', 'P', 'S', 'V', 'Y', 
                             'AB', 'AE', 'AH', 'AK', 'AN', 
                             'AQ', 'AT', 'AW', 'AZ', 'BC']

    # æŸ¥è¯¢ç»“æœåˆ—è¡¨ï¼Œè¿™æ¬¡ä¸éœ€è¦åŒ…å«ä»Šå¤©çš„ç»“æœï¼Œå› ä¸ºæˆ‘ä»¬è®¡ç®—çš„æ˜¯å‘å¸–æ•°å¢é•¿
    dics = {
        "å…³æ³¨æ•°": sheet_columns_followers,
        "å¥½å‹æ•°": sheet_columns_friends
    }

    # è·å–å‰xå¤©çš„å°ç»„å‘å¸–æ•°å¹¶æ·»åŠ åˆ°åˆ—è¡¨ä¸­
    for i, table_col in dics.items():
        query_results_posts = []
        for j in range(0, len(table_col)):
            query_result = query_database2_tk(i, f"'now', '-{j} day'")
            query_results_posts.append(query_result)

        for j, _ in enumerate(query_results_posts):
            if j < len(query_results_posts) - 1:
                query_result_data = count_group(query_results_posts[j], query_results_posts[j+1])
                posts_increase = get_upload_group_increase(ids, query_result_data)
                time.sleep(4)
                upload_data(posts_increase, f"{sheet_name}!{table_col[j]}4:{table_col[j]}", sheet_id)

def upload_tk_fans_increase(sheet_name, sheet_id, ids):
    '''ä¸Šä¼ æ¯æ—¥å¢é•¿çš„ç²‰ä¸æ•°é‡'''
    sheet_columns = ['H', 'K', 'N', 'Q', 'T', 'W', 
                     'Z', 'AC', 'AF', 'AI', 
                     'AL', 'AO', 'AR', 'AU', 'AX', 'BA']

    # æŸ¥è¯¢ç»“æœåˆ—è¡¨ï¼Œåˆå§‹åŒ–åŒ…å«ä»Šå¤©çš„æŸ¥è¯¢ç»“æœ
    query_results = [query_database_tk("'now'")]
    # è·å–å‰10å¤©çš„å°ç»„äººæ•°å¹¶æ·»åŠ åˆ°åˆ—è¡¨ä¸­
    for i in range(1, len(sheet_columns)+1):
        query_result = query_database_tk(f"'now', '-{i} day'")
        query_results.append(query_result)  # å°†ç»“æœæ’å…¥åˆ—è¡¨çš„å¼€å¤´

    for i in range(1, len(query_results)):
        # è®¡ç®—å‰ä¸€å¤©ä¸å½“å‰å¤©çš„å°ç»„äººæ•°å¢é•¿
        query_result_data = count_group(query_results[i-1], query_results[i])
        increase = get_upload_group_increase(ids, query_result_data)
        # ä¸Šä¼ æ•°æ®åˆ°å¯¹åº”çš„åˆ—
        time.sleep(4)
        upload_data(increase, f"{sheet_name}!{sheet_columns[i-1]}4:{sheet_columns[i-1]}", sheet_id)

def job_tk(sheet_id, sheet_name, sheet_range="B4:C"):
    '''æŠ–éŸ³æ•°æ®å¤„ç†'''
    sheet_date = get_data(sheet_name, sheet_range, sheet_id)
    result = sheet_date[0]
    ids = get_group_id(result, 1)

    result_all = list(get_titok_post_info(ids))
    print(result_all, 504)

    upload_data_list = upload_tk_today(sheet_name, sheet_id, result_all) # ä¸Šä¼ ä»Šæ—¥æ•°æ®
    print('ä»Šæ—¥æ•°æ®å·²æ›´æ–°')

    # æ’å…¥æ•°æ®åº“,å§“åï¼ŒIDï¼Œç²‰ä¸æ•°ï¼Œå…³æ³¨æ•°ï¼Œå¥½å‹æ•°ï¼Œç‚¹èµæ•°
    db_data = tk_db_insert(result, tday_, upload_data_list)
    tk_input_database(db_data)

    upload_tk_fans_increase(sheet_name, sheet_id, ids)
    print('ç²‰ä¸æ•°æ®å·²æ›´æ–°')
    upload_tk_fri_fol_increase(sheet_name, sheet_id, ids)
    print('å¥½å‹å’Œå…³æ³¨æ•°æ®å·²æ›´æ–°')

    update_time(sheet_name, sheet_id, "D1", "ç²‰ä¸æ€»æ•°") # æ›´æ–°è¡¨æ ¼æ—¶é—´

def tk_db_insert(group_info, tday, datas):
    """æ’å…¥æ•°æ®åº“çš„æ•°æ®"""
    infos = []
    for row in range(0, group_info.shape[0]):
        group_row = []
        # print(96, value.iat[row, 2])
        group_row.append(group_info.iat[row, 0]),
        group_row.append(group_info.iat[row, 1]),
        group_row.append(tday),
        group_row.append(datas[row][0]),
        group_row.append(datas[row][1]),
        group_row.append(datas[row][2]),
        group_row.append(datas[row][3]),
        infos.append(group_row)
    # print(infos, 531)
    return infos

def process_fb_chunk(sheet_id, sheet_name, ids_chunk, result_chunk):
    """å¤„ç†Facebookæ•°æ®çš„å­é›†"""
    # è·å–å¸–å­å’Œæˆå‘˜æ•°æ®
    result_post_mem_all = getposts(ids_chunk)
    result_posts = result_post_mem_all[0]
    result_members = result_post_mem_all[1]
    
    # å‡†å¤‡æ•°æ®åº“æ’å…¥æ•°æ®
    db_data = db_insert(result_chunk, tday_, result_members, result_posts)
    
    # è¿”å›å¤„ç†ç»“æœ
    return {
        'posts': result_posts,
        'members': result_members,
        'db_data': db_data
    }

def job_fb(sheet_id, sheet_name, timezone, sheet_range="B4:D", chunk_size=4000):
    sheet_date = get_data(sheet_name, sheet_range, sheet_id)
    result = sheet_date[0]
    ids = get_group_id(result)
    
    # æ£€æŸ¥è¡Œæ•°
    row_count = result.shape[0]
    if row_count > chunk_size:
        print(f"è¡Œæ•°è¶…è¿‡{chunk_size}ï¼ˆå½“å‰ä¸º{row_count}ï¼‰ï¼Œä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†")
        
        # è®¡ç®—éœ€è¦çš„çº¿ç¨‹æ•°
        num_chunks = (row_count + chunk_size - 1) // chunk_size  # å‘ä¸Šå–æ•´
        
        # åˆ›å»ºçº¿ç¨‹å’Œç»“æœå®¹å™¨
        threads = []
        results = [None] * num_chunks
        
        # åˆ†å‰²æ•°æ®å¹¶åˆ›å»ºçº¿ç¨‹
        for i in range(num_chunks):
            start_idx = i * chunk_size
            end_idx = min((i + 1) * chunk_size, row_count)
            
            # åˆ›å»ºDataFrameå­é›†
            result_chunk = result.iloc[start_idx:end_idx].copy()
            ids_chunk = ids[start_idx:end_idx]
            
            # åˆ›å»ºå¹¶å¯åŠ¨çº¿ç¨‹
            thread = threading.Thread(
                target=lambda idx=i, r_chunk=result_chunk, i_chunk=ids_chunk: results.__setitem__(idx, process_fb_chunk(sheet_id, sheet_name, i_chunk, r_chunk))
            )
            threads.append(thread)
            thread.start()
            print(f"å¯åŠ¨çº¿ç¨‹ {i+1}/{num_chunks}, å¤„ç†è¡Œ {start_idx+1}-{end_idx}")
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for i, thread in enumerate(threads):
            thread.join()
            print(f"çº¿ç¨‹ {i+1}/{num_chunks} å·²å®Œæˆ")
        
        # åˆå¹¶ç»“æœ
        all_posts = []
        all_members = []
        all_db_data = []
        
        for result in results:
            print(771, result['posts'], result['members'], result['db_data'])
            all_posts.extend(result['posts'])
            all_members.extend(result['members'])
            all_db_data.extend(result['db_data'])
        
        # æ’å…¥æ•°æ®åº“
        input_database(all_db_data)
        # ä¸Šä¼ æˆå‘˜æ•°æ®
        upload_data(all_members, "{}!E4:E".format(sheet_name), sheet_id)
        
    else:
        # åŸæœ‰çš„å•çº¿ç¨‹å¤„ç†é€»è¾‘
        result_post_mem_all = getposts(ids)
        result_posts = result_post_mem_all[0]
        result_members = result_post_mem_all[1]
        
        db_data = db_insert(result, tday_, result_members, result_posts)
        input_database(db_data)

        upload_data(result_members, "{}!E4:E".format(sheet_name), sheet_id)

    
    # æŸ¥è¯¢ç»“æœåˆ—è¡¨ï¼Œåˆå§‹åŒ–åŒ…å«ä»Šå¤©çš„æŸ¥è¯¢ç»“æœ
    query_results = [query_database("'now'")]

    # è·å–å‰10å¤©çš„å°ç»„äººæ•°å¹¶æ·»åŠ åˆ°åˆ—è¡¨ä¸­
    for i in range(1, 34):
        query_result = query_database(f"'now', '-{i} day'")
        query_results.append(query_result)  # å°†ç»“æœæ’å…¥åˆ—è¡¨çš„å¼€å¤´

    # éå†æŸ¥è¯¢ç»“æœï¼Œè®¡ç®—å¢é•¿å¹¶ä¸Šä¼ æ•°æ®
    datas = []
    for i in range(1, len(query_results)):
        # è®¡ç®—å‰ä¸€å¤©ä¸å½“å‰å¤©çš„å°ç»„äººæ•°å¢é•¿
        query_result_data = count_group(query_results[i-1], query_results[i])
        increase = get_upload_group_increase(ids, query_result_data)
        datas.append(increase)

    # æŸ¥è¯¢ç»“æœåˆ—è¡¨ï¼Œè¿™æ¬¡ä¸éœ€è¦åŒ…å«ä»Šå¤©çš„ç»“æœï¼Œå› ä¸ºæˆ‘ä»¬è®¡ç®—çš„æ˜¯å‘å¸–æ•°å¢é•¿
    query_results_posts = []

    # è·å–å‰xå¤©çš„å°ç»„å‘å¸–æ•°å¹¶æ·»åŠ åˆ°åˆ—è¡¨ä¸­
    for i in range(0, 33):
        query_result = query_database2(f"'now', '-{i} day'")
        query_results_posts.append(query_result)

    # éå†æŸ¥è¯¢ç»“æœï¼Œè®¡ç®—å¢é•¿å¹¶ä¸Šä¼ æ•°æ®
    group_posts = []
    for i, result in enumerate(query_results_posts):
        posts_increase = get_upload_group_increase(ids, result)
        group_posts.append(posts_increase)

    # æ‰¹é‡ä¸Šä¼ 
    merged_list = []
    # å‡è®¾æ¯ä¸ªç»„çš„è¡Œæ•°ç›¸åŒ
    num_rows = len(datas[0])
    for r in range(num_rows):
        row = []
        # å¯¹äºæ¯ä¸ªç»„ï¼ˆå‡è®¾ç»„æ•°ä¸€è‡´ï¼‰
        for group in range(len(datas)):
            row.append(datas[group][r][0])
            row.append(group_posts[group][r][0])
        merged_list.append(row)
    upload_data_batch(merged_list, sheet_name, "F4:BS", sheet_id)


def get_sheets(sheet_id, sheet_range="A2:C"):
    sheets = get_data("info", sheet_range, sheet_id)
    return sheets


@click.command()
@click.option("-s", "--sheet_id", help="æ›´æ–°çš„è¡¨æ ¼ ID")
@click.option("-p", "--platform", help="å¹³å°åç§°")
@click.option("-r", "--sheet_range", default="A2:C", help="sheetèŒƒå›´")
@click.option("-c", "--chunk_size", default=4000, type=int, help="å¤šçº¿ç¨‹å¤„ç†æ—¶æ¯ä¸ªçº¿ç¨‹å¤„ç†çš„æœ€å¤§è¡Œæ•°")
@click.option("-t", "--timezone", default="Europe/Berlin", help="æ—¶åŒº")
def main(sheet_id, platform, sheet_range, chunk_size, timezone):
    global tday_
    tday_ = time_now(timezone)
    print("å½“å‰æ—¶é—´:", tday_)
    if platform == "fb":
        sheets_name = get_sheets(sheet_id, sheet_range)
        for sheet in sheets_name[0][0]:
            job_fb(sheet_id, sheet, chunk_size=chunk_size, timezone=timezone)
            update_time(sheet, sheet_id, timezone)
    elif platform == "tiktok":
        sheets_name = get_sheets(sheet_id)
        for sheet in sheets_name[0][0]:
            job_tk(sheet_id, sheet, "B4:C")

if __name__ == "__main__":
    main()
